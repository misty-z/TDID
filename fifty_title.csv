"Item type","Authors","Title","Journal","Publication year","Volume","Issue","Pages","Institution","Publisher","Book title","Proceedings title","Date published","ISBN","ISSN","URLs","DOI","PMID","Arxiv ID","PMC ID","Abstract","Keywords","Notes","Archive prefix","Eprint ID"
"Journal Article","Khemasuwan D,Sorensen JS,Colt HG","Artificial intelligence in pulmonary medicine: Computer vision, predictive model and covid-19","European Respiratory Review","2020","29","157","1-16","","Eur Respiratory Soc","","","2020","","1600-0617","http://dx.doi.org/10.1183/16000617.0181-2020;https://www.ncbi.nlm.nih.gov/pubmed/33004526","10.1183/16000617.0181-2020","33004526","","","Artificial intelligence (AI) is transforming healthcare delivery. The digital revolution in medicine and healthcare information is prompting a staggering growth of data intertwined with elements from many digital sources such as genomics, medical imaging and electronic health records. Such massive growth has sparked the development of an increasing number of AI-based applications that can be deployed in clinical practice. Pulmonary specialists who are familiar with the principles of AI and its applications will be empowered and prepared to seize future practice and research opportunities. The goal of this review is to provide pulmonary specialists and other readers with information pertinent to the use of AI in pulmonary medicine. First, we describe the concept of AI and some of the requisites of machine learning and deep learning. Next, we review some of the literature relevant to the use of computer vision in medical imaging, predictive modelling with machine learning, and the use of AI for battling the novel severe acute respiratory syndrome-coronavirus-2 pandemic. We close our review with a discussion of limitations and challenges pertaining to the further incorporation of AI into clinical pulmonary practice.","artificial intelligent,deep learning,machine learning,pulmonary specialist","Cited By (since 2020): 59","",""
"Miscellaneous","Abudawood GA,Ashi HM,Almarzouki NK","Computer Vision Syndrome among Undergraduate Medical Students in King Abdulaziz University, Jeddah, Saudi Arabia","","2020","2020","","","","hindawi.com","Journal of Ophthalmology","","2020","","2090-0058","https://www.hindawi.com/journals/joph/2020/2789376/;http://dx.doi.org/10.1155/2020/2789376","10.1155/2020/2789376","","","","Introduction. Computer vision syndrome (CVS) is ""a complex of eye and vision problems related to near work experienced during computer use."" It is one of the rising health concerns related to technology (cell phones and tablets) due to continuous use of computers among students. The aim of this study was to determine the prevalence of CVS, associated risk factors, and commonly associated symptoms and to assess the awareness and proper practice of using computers for studying. Methods. A cross-sectional descriptive study was conducted among 651 undergraduate medical students in King Abdulaziz University, Jeddah, Saudi Arabia. An electronic survey was conducted to collect the data. Data were analyzed using SPSS v21. The chi-square test (Fisher's exact test when required) was used to study the significance of associations. P value <0.05 was considered statistically significant. Results. High prevalence of CVS was observed, in which 95% (558) reported at least one symptom during studying using computers. Most frequently reported symptoms were excessive tearing and neck, shoulder, or back pain. Female students had a higher risk of CVS (P=0.003). Students who are myopic or hyperopic showed no association. Astigmatism was associated significantly with CVS (P=0.03). Using spectacles or contact lens showed no association. Students with dry eye disease revealed a significant association with CVS (P=0.01). The most significant risk factors related to the daily usage of computer were longer duration of studying (P<0.001), short distance from the screen (P<0.05), and high brightness of the screen (P<0.05). The most significant preventive measure taken to relieve the symptoms was applying the 20-20-20 rule. Conclusion. CVS is common among medical students; significant risk factors need to be addressed to reduce the symptom and to ensure a better productivity of work. It is a necessity to raise awareness among medical students regarding computer-related health problems.","computer vision syndrome,dry eye disease","Cited By (since 2020): 60","",""
"Journal Article","Akbarian S,Cawston T,Moreno L,Patel S,Allen V,Dolatabadi E","A Computer Vision Approach to Combat Lyme Disease","arXiv preprint arXiv \ldots","2020","","","","","arxiv.org","","","2020","","","http://arxiv.org/abs/2009.11931","","","2009.11931","","Lyme disease is an infectious disease transmitted to humans by a bite from an infected Ixodes species (blacklegged ticks). It is one of the fastest growing vector-borne illness in North America and is expanding its geographic footprint. Lyme disease treatment is time-sensitive, and can be cured by administering an antibiotic (prophylaxis) to the patient within 72 hours after a tick bite by the Ixodes species. However, the laboratory-based identification of each tick that might carry the bacteria is time-consuming and labour intensive and cannot meet the maximum turn-around-time of 72 hours for an effective treatment. Early identification of blacklegged ticks using computer vision technologies is a potential solution in promptly identifying a tick and administering prophylaxis within a crucial window period. In this work, we build an automated detection tool that can differentiate blacklegged ticks from other ticks species using advanced deep learning and computer vision approaches. We demonstrate the classification of tick species using Convolution Neural Network (CNN) models, trained end-to-end from tick images directly. Advanced knowledge transfer techniques within teacher-student learning frameworks are adopted to improve the performance of classification of tick species. Our best CNN model achieves 92% accuracy on test set. The tool can be integrated with the geography of exposure to determine the risk of Lyme disease infection and need for prophylaxis treatment.","Computer Vision,Convolution Neural Network,Ixodes,Knowledge Transfer,Lyme disease","Cited By (since 2020): 3","arXiv","2009.11931"
"Journal Article","Meske C,Bunde E","Transparency and trust in human-AI-interaction: The role of model-agnostic explanations in computer vision-based decision support","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","2020","12217 LNCS","","54-69","","Springer","","","2020","","1611-3349","http://dx.doi.org/10.1007/978-3-030-50334-5_4","10.1007/978-3-030-50334-5_4","","","","Computer Vision, and hence Artificial Intelligence-based extraction of information from images, has increasingly received attention over the last years, for instance in medical diagnostics. While the algorithms' complexity is a reason for their increased performance, it also leads to the ‘black box' problem, consequently decreasing trust towards AI. In this regard, “Explainable Artificial Intelligence” (XAI) allows to open that black box and to improve the degree of AI transparency. In this paper, we first discuss the theoretical impact of explainability on trust towards AI, followed by showcasing how the usage of XAI in a health-related setting can look like. More specifically, we show how XAI can be applied to understand why Computer Vision, based on deep learning, did or did not detect a disease (malaria) on image data (thin blood smear slide images). Furthermore, we investigate, how XAI can be used to compare the detection strategy of two different deep learning models often used for Computer Vision: Convolutional Neural Network and Multi-Layer Perceptron. Our empirical results show that i) the AI sometimes used questionable or irrelevant data features of an image to detect malaria (even if correctly predicted), and ii) that there may be significant discrepancies in how different deep learning models explain the same prediction. Our theoretical discussion highlights that XAI can support trust in Computer Vision systems, and AI systems in general, especially through an increased understandability and predictability.","Artificial Intelligence,Computer Vision,Deep learning,Explainability,Healthcare,Trust","Cited By (since 2020): 38","",""
"Miscellaneous","Fernandes AF,Dórea JR,Rosa GJ","Image Analysis and Computer Vision Applications in Animal Sciences: An Overview","","2020","7","","","","frontiersin.org","Frontiers in Veterinary Science","","2020","","2297-1769","https://www.frontiersin.org/articles/10.3389/fvets.2020.551269/full;http://dx.doi.org/10.3389/fvets.2020.551269","10.3389/fvets.2020.551269","","","","Computer Vision, Digital Image Processing, and Digital Image Analysis can be viewed as an amalgam of terms that very often are used to describe similar processes. Most of this confusion arises because these are interconnected fields that emerged with the development of digital image acquisition. Thus, there is a need to understand the connection between these fields, how a digital image is formed, and the differences regarding the many sensors available, each best suited for different applications. From the advent of the charge-coupled devices demarking the birth of digital imaging, the field has advanced quite fast. Sensors have evolved from grayscale to color with increasingly higher resolution and better performance. Also, many other sensors have appeared, such as infrared cameras, stereo imaging, time of flight sensors, satellite, and hyperspectral imaging. There are also images generated by other signals, such as sound (ultrasound scanners and sonars) and radiation (standard x-ray and computed tomography), which are widely used to produce medical images. In animal and veterinary sciences, these sensors have been used in many applications, mostly under experimental conditions and with just some applications yet developed on commercial farms. Such applications can range from the assessment of beef cuts composition to live animal identification, tracking, behavior monitoring, and measurement of phenotypes of interest, such as body weight, condition score, and gait. Computer vision systems (CVS) have the potential to be used in precision livestock farming and high-throughput phenotyping applications. We believe that the constant measurement of traits through CVS can reduce management costs and optimize decision-making in livestock operations, in addition to opening new possibilities in selective breeding. Applications of CSV are currently a growing research area and there are already commercial products available. However, there are still challenges that demand research for the successful development of autonomous solutions capable of delivering critical information. This review intends to present significant developments that have been made in CVS applications in animal and veterinary sciences and to highlight areas in which further research is still needed before full deployment of CVS in breeding programs and commercial farms.","automation,computer vision,high-throughput phenotyping,imaging,livestock,phenotyping,precision livestock,sensors","Cited By (since 2020): 53","",""
"Journal Article","Tombe R","Computer Vision for Smart Farming and Sustainable Agriculture","2020 IST-Africa Conference, IST-Africa 2020","2020","","","","","ieeexplore.ieee.org","","","2020","","","","","","","","Developments in satellite technology, remote sensors and drone technologies are mushrooming. These developments yield volumes of high quality scene images that require effective processing for intelligent farming applications. The recent deep learning technologies can leverage these opportunities to fuse computer vision and artificial intelligence in farming. This encompasses the big data phenomena and huge volumes of data that are captured, processed and applied for decision-making. This paper aims to give insights on the integration of computer vision for smart farming in-order to attain sustainable agriculture. Using a structured approach, this research proposes a computer vision technique for crop image feature characterization that applies in the determination of the crop's health status. To achieve this, a deep convolutional network is applied for image feature extraction and representation, and then these features are fed to the support vector-learning machine for training and subsequent image interpretation. From the experimental results, it is evident that the proposed technique generates superior visual interpretation results of scene images as compared to other methods in literature. It follows that the Global food security and agricultural sustainability can be attained through ICT enabled solutions that are integrates and works together a phenomenon referred to as smart farming.","big data processing,computer vision,deep learning,drones,machine learning,remote sensing images","Cited By (since 2020): 19","",""
"Miscellaneous","An R,Man Y,Iram S,Kucukal E,Hasan MN,Solis-Fuentes A,Bode A,Hill A,Cheng K,Huang Y,Ahuja S,Little JA,Hinczewski M,Gurkan UA","Computer Vision and Deep Learning Assisted Microchip Electrophoresis for Integrated Anemia and Sickle Cell Disease Screening","","2020","136","Supplement 1","46-47","","Elsevier","Blood","","2020","","0006-4971","https://www.sciencedirect.com/science/article/pii/S0006497118694170;http://dx.doi.org/10.1182/blood-2020-142548","10.1182/blood-2020-142548","","","","Introduction: Anemia affects a third of the world's population with the heaviest burden borne by women and children. Anemia leads to preventable impaired development in children, as well as high morbidity and early mortality among sufferers. Inherited hemoglobin (Hb) disorders, such as sickle cell disease (SCD), are associated with chronic hemolytic anemia causing high morbidity and mortality. Anemia and SCD are inherently associated and are both prevalent in the same regions of the world including sub-Saharan Africa, India, and south-east Asia. Anemia and SCD-related complications can be mitigated by screening, early diagnosis followed by timely intervention. Anemia treatment depends on the accurate characterization of the cause, such as inherited Hb disorders. Meanwhile, Hb disorders or SCD treatments, such as hydroxyurea therapy, requires close monitoring of blood Hb level and the patient's anemia status over time. As a result, it is crucially important to perform integrated detection and monitoring of blood Hb level, anemia status, and Hb variants, especially in areas where anemia and inherited Hb disorders are the most prevalent. Blood Hb level (in g/dL) is used as the main indicator of anemia, while the presence of Hb variants (e.g., sickle Hb or HbS) in blood is the primary indicator of an inherited disorder. The current clinical standards for anemia testing and Hb variant identification are complete blood count (CBC) and High-Performance Liquid Chromatography (HPLC), respectively. State-of-the-art laboratory infrastructure and trained personnel are required for these laboratory tests. However, these resources are typically scarce in low- and middle-income countries, where anemia and Hb disorders are the most prevalent. As a result, there is a dire need for high accuracy portable point-of-care (POC) devices to perform integrated anemia and Hb variant tests with affordable cost and high throughput.Methods: In 2019, the World Health Organization (WHO) listed Hb electrophoresis as an essential in vitro diagnostic (IVD) technology for diagnosing SCD and sickle cell trait. We have leveraged the common Hb electrophoresis method and developed a POC microchip electrophoresis test, Hemoglobin Variant/Anemia (HbVA). This technology is being commercialized under the product name ""Gazelle"" by Hemex Health Inc. for Hb variant identification with integrated anemia detection (Fig. 1A&B). We hypothesized that computer vision and deep learning will enhance the accuracy and reproducibility of blood Hb level prediction and anemia detection in cellulose acetate based Hb electrophoresis, which is a clinical standard test for Hb variant screening and diagnosis worldwide (Fig. 1C). To test this hypothesis, we integrated, for the first time, a new, computer vision and artificial neural network (ANN) based deep learning imaging and data analysis algorithm, to Hb electrophoresis. Here, we show the feasibility of this new, computer vision and deep learning enabled diagnostic approach via testing of 46 subjects, including individuals with anemia and homozygous (HbSS) or heterozygous (HbSC or S$\beta$-thalassemia) SCD.Results and Discussion: HbVA computer vision tracked the electrophoresis process real-time and the deep learning neural network algorithm determined Hb levels which demonstrated significant correlation with a Pearson Correlation Coefficient of 0.95 compared to the results of reference standard CBC (Fig.1D). Furthermore, HbVA demonstrated high reproducibly with a mean absolute error of 0.55 g/dL and a bias of -0.10 g/dL (95% limits of agreement: 1.5 g/dL) according to Bland-Altman analysis (Fig. 1E). Anemia determination was achieved with 100% sensitivity and 92.3% specificity with a receiver operating characteristic area under the curve (AUC) of 0.99 (Fig. 1F). Within the same test, subjects with SCD were identified with 100% sensitivity and specificity (Fig. 1G). Overall, the results suggested that computer vision and deep learning methods can be used to extract new information from Hb electrophoresis, enabling, for the first time, reproducible, accurate, and integrated blood Hb level prediction, anemia detection, and Hb variant identification in a single affordable test at the POC.","anemia,artificial neural network,computer vision,deep learning","Cited By (since 2020): 4","",""
"Miscellaneous","Okinda C,Nyalala I,Korohou T,Okinda C,Wang J,Achieng T,Wamalwa P,Mang T,Shen M","A review on computer vision systems in monitoring of poultry: A welfare perspective","","2020","4","","184-208","","Elsevier","Artificial Intelligence in Agriculture","","2020","","2589-7217","https://www.sciencedirect.com/science/article/pii/S2589721720300258;http://dx.doi.org/10.1016/j.aiia.2020.09.002","10.1016/j.aiia.2020.09.002","","","","Monitoring of poultry welfare-related bio-processes and bio-responses is vital in welfare assessment and management of welfare-related factors. With the current development in information technologies, computer vision has become a promising tool in the real-time automation of poultry monitoring systems due to its non-intrusive and non-invasive properties, and its ability to present a wide range of information. Hence, it can be applied to monitor several bio-processes and bio-responses. This review summarizes the current advances in poultry monitoring techniques based on computer vision systems, i.e., conventional machine learning-based and deep learning-based systems. A detailed presentation on the machine learning-based system was presented, i.e., pre-processing, segmentation, feature extraction, feature selection, and dimension reduction, and modeling. Similarly, deep learning approaches in poultry monitoring were also presented. Lastly, the challenges and possible solutions presented by researches in poultry monitoring, such as variable illumination conditions, occlusion problems, and lack of augmented and labeled poultry datasets, were discussed.","Computer vision,Deep learning,Machine learning,Monitoring,Poultry,Welfare","Cited By (since 2020): 47","",""
"Journal Article","Muñoz JP,Boger R,Dexter S,Low R","Mosquitoes and Public Health: Improving Data Validation of Citizen Science Contributions Using Computer Vision","\ldots Health and Wellness Management \ldots","2020","","","469-493","","Springer","","","2020","","","http://dx.doi.org/10.1007/978-3-030-17347-0_23","10.1007/978-3-030-17347-0_23","","","","Citizen scientists have the potential to play an important role in combating mosquito-borne diseases such as malaria, dengue fever, Zika, and West Nile virus. While public health officials do not have the labor or resources to collect adequate spatial and temporal coverage of where, when, and what types of mosquitoes are found, these officials may be hesitant to include citizen science data because they are not confident of the data. The GLOBE Observer Mosquito Habitat Mapper (GO MHM) app was launched in 2017, and data are being collected from around the world. As part of the app, photos of mosquito larvae are submitted. Computer vision software provides a means of assisting in the validation of the images for correctness. We have developed an image recognition prototype that includes image collection, training of image classifiers, specimen recognition, and expert validation and analytics. Photos of known mosquito larvae are used to train a Deep Learning classification model. Citizen scientists submit photos, and the system conducts an analysis that indicates the probability of correct mosquito identification. New and better classification models can be trained from new data received from citizen scientists. Experts can have access to the recognition results to assess data quality and devise ways to improve the quality of GO MHM data, while public health officials can use the data to assist in the mitigation of disease outbreaks. Recommendations are made for prototype improvements.","Citizen science,Computer vision,Mosquitoes,Public health,Vector-borne diseases","Cited By (since 2020): 9","",""
"Journal Article","Fernández-Carrión E,Barasona JÁ,Sánchez Á,Jurado C,Cadenas-Fernández E,Sánchez-Vizcaíno JM","Computer vision applied to detect lethargy through animal motion monitoring: A trial on african swine fever inwild boar","Animals","2020","10","12","1-12","","mdpi.com","","","2020","","2076-2615","http://dx.doi.org/10.3390/ani10122241","10.3390/ani10122241","","","","Early detection of infectious diseases is the most cost-effective strategy in disease surveillance for reducing the risk of outbreaks. Latest deep learning and computer vision improvements are powerful tools that potentially open up a new field of research in epidemiology and disease control. These techniques were used here to develop an algorithm aimed to track and compute animal motion in real time. This algorithm was used in experimental trials in order to assess African swine fever (ASF) infection course in Eurasian wild boar. Overall, the outcomes showed negative correlation between motion reduction and fever caused by ASF infection. In addition, infected animals computed significant lower movements compared to uninfected animals. The obtained results suggest that a motion monitoring system based on artificial vision may be used in indoors to trigger suspicions of fever. It would help farmers and animal health services to detect early clinical signs compatible with infectious diseases. This technology shows a promising non-intrusive, economic and real time solution in the livestock industry with especial interest in ASF, considering the current concern in the world pig industry.","African swine fever,Artificial intelligence,Computer vision,Infectious disease","Cited By (since 2020): 7","",""
"Journal Article","Punia R,Kumar L,Mujahid M,Rohilla R","Computer vision and radiology for COVID-19 detection","2020 International Conference for Emerging Technology, INCET 2020","2020","","","","","ieeexplore.ieee.org","","","2020","","","http://dx.doi.org/10.1109/INCET49848.2020.9154088","10.1109/INCET49848.2020.9154088","","","","COVID-19 is spreading rapidly throughout the world. As of 14 April 2020, 128, 000 people died of COVID-19, while 1.99 million cases in 210 countries and territories were reported in 219.747 cases. As the virus spreads at a very high rate, there is a huge shortage of medical testing kits all over the world. The respiratory system is the part of the human body most affected by the virus, so the use of X-rays of the chest may prove to be a more efficient way than the thermal screening of the human body. In this paper, we are trying to develop a method that uses radiology, i.e. X-rays for detecting the novel coronavirus. Along with the paper, we also release a dataset for the research community and further development extracted from various medical research hospital facilities treating COVID-19 patients.","COVID-19,Computer Vision,Radiology","Cited By (since 2020): 37","",""
"Journal Article","Sánchez-Valerio MR,Mohamed-Noriega K,Zamora-Ginez I,Duarte BG,Vallejo-Ruiz V","Dry eye disease association with computer exposure time among subjects with computer vision syndrome","Clinical Ophthalmology","2020","14","","4311-4317","","Taylor &Francis","","","2020","","1177-5483","http://dx.doi.org/10.2147/OPTH.S252889","10.2147/OPTH.S252889","","","","Purpose: To assess the time of exposure to the computer and dry eye disease (DED) in subjects with computer vision syndrome (CVS). Methods: A cross-sectional study was conducted in office workers, computer users of both sexes, with an age range of 18–45 years without comorbidities; we included 108 subjects divided into 3 groups according to the time of computer exposure in hours per day (H/D): 8 (n = 39). A specific questionnaire was applied to them on the exposure time and the type of visual display terminal (VDT) used, as well as the computer vision symptoms scale (CVSS17). DED was diagnosed with the Ocular Surface Disease Index (OSDI). Ocular surface damage and signs of DED were evaluated with the tear rupture time test (TBUT), the integrity of the ocular surface by ocular surface staining (OSS) and the production of the aqueous basal tear film using the Schirmer test. Results: Average computer exposure time, measured differently, was positively correlated with DED development. The computer exposure time measured in hours per year and TBUT showed a significant negative correlation (p <0.001) (rho −0.463). Years of computer exposure and staining of the ocular surface showed a significant positive correlation (p <0 0.001; rho 0.404). The accumu-lated exposure time was negatively correlated with TBUT (p <0.001; rho −0.376) and positively with OSS (p <0.001; rho 0.433). Schirmer test did not correlate with computer exposure time. Conclusion: The prolonged time of exposure to the computer in subjects with CVS was significantly correlated with the DED tests, in the different ways of measuring it; but not with the Schirmer test.","Computer vision syndrome,Dry eye disease","Cited By (since 2020): 43","",""
"Conference Paper","Jain Y,Gandhi H,Burte A,Vora A","Mental and Physical Health Management System Using ML, Computer Vision and IoT Sensor Network","","2020","","","786-791","IEEE","","","Proceedings of the 4th International Conference on Electronics, Communication and Aerospace Technology, ICECA 2020","2020","9781728163871","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9297447;http://dx.doi.org/10.1109/ICECA49313.2020.9297447","10.1109/ICECA49313.2020.9297447","","","","Previously, healthcare management systems were particularly focused on physical health and disregarded the mental health. With technology that encompass all spheres of life, the benefits of technology in healthcare remain unfathomable. A person's emotion, body temperature and heart rate can provide insightful information on both mind and body. This paper demonstrates a complete healthcare management system that considers both physical as well as mental health. IoT sensor network and Arduino UNO is used to collect a person's body temperature and heart rate and simultaneously stored in a database. The paper also includes an emotion recognition unit that is built using the MiniXception convolutional neural network architecture to keep a track of the person's emotion. A natural language processing chatbot has been employed to enable a virtual doctor for the user and help the user to provide a preliminary diagnosis. Furthermore, the tools like HTMI5 and CSS have been employed to build the user interface. The data obtained is then stored using MySQL database service. The results of this implementation indicates that the proposed system can reduce the workload for doctors, to be more aware of their physical and mental health and lastly the proposed methodology will make healthcare to be more accessible.","Arduino UNO,Chatbot,Image processing,IoT,convolutional neural network","","",""
"Miscellaneous","Kakani V,Nguyen H,Kumar BP,Kim H,Pasupuleti VR","A critical review on computer vision and artificial intelligence in food industry","","2020","2","","","","Elsevier","Journal of Agriculture and Food Research","","2020","","2666-1543","https://www.sciencedirect.com/science/article/pii/S2666154320300144;http://dx.doi.org/10.1016/j.jafr.2020.100033","10.1016/j.jafr.2020.100033","","","","Emerging technologies such as computer vision and Artificial Intelligence (AI) are estimated to leverage the accessibility of big data for active training and yielding operational real time smart machines and predictable models. This phenomenon of applying vision and learning methods for the improvement of food industry is termed as computer vision and AI driven food industry. This review contributes to provide an insight into state-of-the-art AI and computer vision technologies that can assist farmers in agriculture and food processing. This paper investigates various scenarios and use cases of machine learning, machine vision and deep learning in global perspective with the lens of sustainability. It explains the increasing demand towards the AgTech industry using computer vision and AI which might be a path towards sustainable food production to feed the future. Also, this review tosses some implications regarding challenges and recommendations in inclusion of technologies in real time farming, substantial global policies and investments. Finally, the paper discusses the possibility of using Fourth Industrial Revolution [4.0 IR] technologies such as deep learning and computer vision robotics as a key for sustainable food production.","Artificial intelligence,Autonomous navigation,Computer vision,Sustainable food supply","Cited By (since 2020): 168","",""
"Journal Article","Paul A,Ghosh S,Das AK,Goswami S,Das Choudhury S,Sen S","A Review on Agricultural Advancement Based on Computer Vision and Machine Learning","Advances in Intelligent Systems and Computing","2020","937","","567-581","","Springer","","","2020","","2194-5365","http://dx.doi.org/10.1007/978-981-13-7403-6_50","10.1007/978-981-13-7403-6_50","","","","The importance of agriculture in modern society need not be overstated. In order to meet the huge requirements of food and to mitigate, the conventional problems of cropping smart and sustainable agriculture have emerged over the conventional agriculture. From computational perspective, computer vision and machine learning techniques have been applied in many aspects of human and social life, and agriculture is not also an exception. This review paper gives an overview of machine learning and computer vision techniques which are inherently associated with this domain. A summary of the works highlighting different seeds, crops, fruits with the country is also enclosed. The paper also tries to give an analysis, which can help researchers to look at some relevant problems in the context of India.","Agriculture,Computer vision,Machine learning,Plant phenotyping","Cited By (since 2020): 27","",""
"Miscellaneous","Tripathi MK,Maktedar DD","A role of computer vision in fruits and vegetables among various horticulture products of agriculture fields: A survey","","2020","7","2","183-203","","Elsevier","Information Processing in Agriculture","","2020","","2214-3173","https://www.sciencedirect.com/science/article/pii/S2214317318303834;http://dx.doi.org/10.1016/j.inpa.2019.07.003","10.1016/j.inpa.2019.07.003","","","","Computer vision is a consistent and advanced technique for image processing, with the propitious outcome, and enormous potential. A computer vision has been strongly adopted in the heterogeneous domain including agriculture. During the study of existing research on the role of computer vision in fruits and vegetables among various horticulture products of agriculture fields it is noticed that, the existing survey paper has not focused properly on mathematical framework, feature descriptor, defect detection on multiple datasets of fruits and vegetables elaborately. This has motivated us to undertake an extensive survey. In this paper, we examine the paper broadly related to fruits and vegetables among various horticulture products of agriculture fields, specific model, data pre-processing, data analysis method and overall value of performance accuracy by using a particular performance metric. Moreover, we study the different type of disease present in various fruit and vegetable. We have also focused on the comparison of different machine learning approach with respect to different performance metrics on the same dataset. Thus, we have found that among all existing machine learning techniques SVM give better classification accuracy. A generalized framework to grade the quality and defect detection of multiple fruits and vegetables is also proposed in this survey. This paper covers the survey of ninety-eight papers closely related to computer vision in the agricultural field. By the survey, we have found that computer vision plays an important role and has a large potential to address the challenges related to the agricultural fields.","Agriculture,Computer vision,Data-analysis,Defect detection,Descriptor,Monitoring,Pre-processing,Survey","Cited By (since 2020): 79","",""
"Journal Article","Gazzah S,Bencharef O","A Survey on how computer vision can response to urgent need to contribute in COVID-19 pandemics","2020 International Conference on Intelligent Systems and Computer Vision, ISCV 2020","2020","","","","","ieeexplore.ieee.org","","","2020","","","http://dx.doi.org/10.1109/ISCV49265.2020.9204043","10.1109/ISCV49265.2020.9204043","","","","The coronavirus first outbreak in Wuhan city of China by December 2019. Due to its highly contagious power, they spread promptly in the four continents. Moreover, it devastating our daily lives and cause huge economic damage. Therefore, it is urgent to detect the positive cases at the earliest and put then under isolation. Automatic virus detection using Machine Learning will be a valuable contribution to prevent the spread of this epidemic. The purpose of this paper is to present short reviews on the coronavirus detection. In reviewing the existing works, we summarized and compared some related works performed on a collection of CT and X-ray images provided from infected patients. We conclude the paper with some discussions on how computer vision can response to urgent need to contribute in pandemics and to investigate many aspects of new viral replication and pathogenesis.","CNN,COVID-19,CT image,Computer vision,X-ray image,coronavirus detection,deep learning","Cited By (since 2020): 14","",""
"Journal Article","Singh U,Srivastava A,Chauhan D,Singh A","Computer Vision Technique for Detection of Grape Esca (Black Measles) Disease from Grape Leaf Samples","2020 International Conference on Contemporary Computing and Applications, IC3A 2020","2020","","","110-115","","ieeexplore.ieee.org","","","2020","","","http://dx.doi.org/10.1109/IC3A48958.2020.233281","10.1109/IC3A48958.2020.233281","","","","Grape Cultivation requires a periodic and preventive monitoring and adoption of diagnosis mechanisms for the management of diseases and for reducing the aesthetic and economic damages which are induced by the plant diseases. Grapevine Measles, also called Esca, Black Measles or Spanish Measles, is one of cataclysmic disease found in grape plant. This paper proposes an automatic computer vision method to discover the Black Measles disease from the image samples of grape leaves. Multi-channel analysis is performed to metamorphose the leaves from backdrop, followed by the identification and subjugation of the disease affected portion in the leaf image for diagnosis. Global Thresholding is followed by some mathematical morphological operations in order to precisely decline the noisy pixels. Statistical features extraction is performed and fed to a SVM classifier. The propound algorithm successfully acknowledged the affected parts present in the grape leaf images and achieved an accuracy of 97. 2% which makes the proposed algorithm robust and systematized for identification of grape leaves diseases using image processing methods.","Features Extraction,Grape Esca (Black Measles),Metamorphose,SVM (Support Vector Machine)","Cited By (since 2020): 4","",""
"Miscellaneous","Tian H,Wang T,Liu Y,Qiao X,Li Y","Computer vision technology in agricultural automation —A review","","2020","7","1","1-19","","Elsevier","Information Processing in Agriculture","","2020","","2214-3173","https://www.sciencedirect.com/science/article/pii/S2214317319301751;http://dx.doi.org/10.1016/j.inpa.2019.09.006","10.1016/j.inpa.2019.09.006","","","","Computer vision is a field that involves making a machine “see”. This technology uses a camera and computer instead of the human eye to identify, track and measure targets for further image processing. With the development of computer vision, such technology has been widely used in the field of agricultural automation and plays a key role in its development. This review systematically summarizes and analyzes the technologies and challenges over the past three years and explores future opportunities and prospects to form the latest reference for researchers. Through the analyses, it is found that the existing technology can help the development of agricultural automation for small field farming to achieve the advantages of low cost, high efficiency and high precision. However, there are still major challenges. First, the technology will continue to expand into new application areas in the future, and there will be more technological issues that need to be overcome. It is essential to build large-scale data sets. Second, with the rapid development of agricultural automation, the demand for professionals will continue to grow. Finally, the robust performance of related technologies in various complex environments will also face challenges. Through analysis and discussion, we believe that in the future, computer vision technology will be combined with intelligent technology such as deep learning technology, be applied to every aspect of agricultural production management based on large-scale datasets, be more widely used to solve the current agricultural problems, and better improve the economic, general and robust performance of agricultural automation systems, thus promoting the development of agricultural automation equipment and systems in a more intelligent direction.","Agricultural automation,Computer vision,Image processing,Intelligent detection","Cited By (since 2020): 270","",""
"Miscellaneous","Vinitha V,Velantina V","Covid-19 Facemask Detection With Deep Learning and Computer Vision","","2020","07","08","3127-3132","","academia.edu","International Research Journal of Engineering and Technology (IRJET)","","2020","","","www.irjet.net","","","","","The corona virus COVID-19 pandemic is causing a pandemics, and to classify vulnerable populations.The global health crisis so the effective protection methods is provision of healthcare needs funding for emerging wearing a face mask in public areas according to the World technology such as artificial intelligence, IoT, big data and Health Organization (WHO). The COVID-19 pandemic forced machine learning to tackle and predict new diseases. In governments across the world to impose lockdowns to prevent order to better understand infection rates and to trace and virus transmissions. Reports indicate that wearing face masks quickly detect infections, the AI's power is being exploited to while at work clearly reduces the risk of transmission. An address the Covid-19 pandemic. People are forced by laws to efficient and economic approach of using AI to create a safe wear face masks in public in many countries. These rules and environment in a manufacturing setup. A hybrid model using laws were developed as an action to the exponential growth deep and classical machine learning for face mask detection in cases and deaths in many areas. However, the process of will be presented. A face mask detection dataset consists of monitoring large groups of people is becoming more with mask and without mask images , we are going to use difficult. The monitoring process involves the detection of OpenCV to do real-time face detection from a live stream via anyone who is not wearing a face mask. our webcam. We will use the dataset to build a COVID-19 face mask detector with computer vision using Python, OpenCV, Here we introduce a mask face detection model that is based and Tensor Flow and Keras. Our goal is to identify whether the on computer vision and deep learning. The proposed model person on image/video stream is wearing a face mask or not can be integrated with surveillance cameras to impede the with the help of computer vision and deep learning.","computer vision,deep learning,opencv","Cited By (since 2021): 54","",""
"Journal Article","Sánchez-Brau M,Domenech-Amigot B,Brocal-Fernández F,Quesada-Rico JA,Seguí-Crespo M","Prevalence of Computer Vision Syndrome and Its Relationship with Ergonomic and Individual Factors in Presbyopic VDT Workers Using Progressive Addition Lenses","International journal of environmental research and public health","2020","17","3","","","mdpi.com","","","2020","","1660-4601","http://dx.doi.org/10.3390/ijerph17031003;https://www.ncbi.nlm.nih.gov/pubmed/32033372","10.3390/ijerph17031003","32033372","","","This cross-sectional study estimated computer vision syndrome (CVS) prevalence and analysed its relationship with video display terminal (VDT) exposure, as well as sociodemographic, refractive, environmental, and ergonomic characteristics in 109 presbyopic VDT workers wearing progressive addition lenses (PALs). Usual spectacles were measured with a lens analyser, and subjective refraction was performed by an optometrist. CVS was measured with the CVS-Q\textcopyright. VDT exposure was collected. Ergonomic evaluations were conducted in a normal working posture looking at the screen. Air temperature and relative humidity were measured (thermohygrometer), and illumination was measured (luxmeter). Descriptive analysis and differences in CVS prevalence, as a function of the explanatory variables, were performed (chi-square test). Multivariate logistic regression was used to identify factors associated with CVS (OR and 95% CI). The mean age was 54.0 ± 4.8 years, and 43.1% were women. The mean hours of VDT use at work was 6.5 ± 1.3 hours/day. The prevalence of CVS was 74.3%. CVS was significantly associated with women (OR 3.40; 95% CI, 1.12-10.33), non-neutral neck posture (OR 3.27; 95% CI, 1.03-10.41) and altered workplace lighting (OR 3.64; 95% CI, 1.22-10.81). Providing training and information to workers regarding the importance of adequate lighting and ergonomic postures during VDT use is advised to decrease CVS and increase workplace quality of life.","computer vision syndrome,ergonomics,presbyopia,progressive addition lenses,video display terminals,workplace","Cited By (since 2020): 53","",""
"Miscellaneous","Al Tawil L,Aldokhayel S,Zeitouni L,Qadoumi T,Hussein S,Ahamed SS","Prevalence of self-reported computer vision syndrome symptoms and its associated factors among university students","","2020","30","1","189-195","","journals.sagepub.com","European Journal of Ophthalmology","","2020","","1120-6721","https://journals.sagepub.com/doi/pdf/10.1177/1120672118815110;http://dx.doi.org/10.1177/1120672118815110;https://www.ncbi.nlm.nih.gov/pubmed/30474390","10.1177/1120672118815110","30474390","","","Purpose: To determine the prevalence of symptoms of computer vision syndrome and to identify its associated factors. The secondary objective was to assess knowledge and practices related to preventing computer vision syndrome symptoms. Methods: The data for this cross-sectional study were collected through a self-administered questionnaire distributed to 713 female undergraduates studying business and medicine in Saudi Arabia. The questionnaire included computer vision syndrome validated symptoms and factors associated with computer vision syndrome development. Results: The most common symptom due to prolonged computer use was neck or shoulder pain, reported by 82.2% of the subjects. Overall, 66.5% of the subjects suffered from headache and 51.5% from dry eyes, in mild, moderate, or severe form. Business students were 1.6 times as likely as medical students to suffer from computer vision syndrome (odds ratio = 1.65; 95% confidence interval: 1.22, 2.24). The use of electronic devices for more than 5 h (odds ratio = 1.52; 95% confidence interval: 1.07, 2.16) was also associated with experiencing computer vision syndrome symptoms. Regarding computer vision syndrome prevention, factors such as hours of use, screen distance, screen brightness, and room illumination showed statistically significant difference between the two groups (p < 0.0001). Conclusion: The prevalence of computer vision syndrome symptoms was significantly higher among business students, who reported lower awareness and poor practice measures of computer use recommendations. Relevant awareness campaigns focusing on the appropriate use of computers are highly recommended.","Computer vision syndrome,Saudi Arabia,electronic devices,university students,vision problems","Cited By (since 2020): 120","",""
"Miscellaneous","Williams S,Zhao Z,Hafeez A,Wong DC,Relton SD,Fang H,Alty JE","The discerning eye of computer vision: Can it measure Parkinson's finger tap bradykinesia?","","2020","416","","","","Elsevier","Journal of the Neurological Sciences","","2020","","1878-5883","https://www.sciencedirect.com/science/article/pii/S0022510X20303403;http://dx.doi.org/10.1016/j.jns.2020.117003;https://www.ncbi.nlm.nih.gov/pubmed/32645513","10.1016/j.jns.2020.117003","32645513","","","Objective: The worldwide prevalence of Parkinson's disease is increasing. There is urgent need for new tools to objectively measure the condition. Existing methods to record the cardinal motor feature of the condition, bradykinesia, using wearable sensors or smartphone apps have not reached large-scale, routine use. We evaluate new computer vision (artificial intelligence) technology, DeepLabCut, as a contactless method to quantify measures related to Parkinson's bradykinesia from smartphone videos of finger tapping. Methods: Standard smartphone video recordings of 133 hands performing finger tapping (39 idiopathic Parkinson's patients and 30 controls) were tracked on a frame-by-frame basis with DeepLabCut. Objective computer measures of tapping speed, amplitude and rhythm were correlated with clinical ratings made by 22 movement disorder neurologists using the Modified Bradykinesia Rating Scale (MBRS) and Movement Disorder Society revision of the Unified Parkinson's Disease Rating Scale (MDS-UPDRS). Results: DeepLabCut reliably tracked and measured finger tapping in standard smartphone video. Computer measures correlated well with clinical ratings of bradykinesia (Spearman coefficients): −0.74 speed, 0.66 amplitude, −0.65 rhythm for MBRS; −0.56 speed, 0.61 amplitude, −0.50 rhythm for MDS-UPDRS; −0.69 combined for MDS-UPDRS. All p <.001. Conclusion: New computer vision software, DeepLabCut, can quantify three measures related to Parkinson's bradykinesia from smartphone videos of finger tapping. Objective ‘contactless' measures of standard clinical examinations were not previously possible with wearable sensors (accelerometers, gyroscopes, infrared markers). DeepLabCut requires only conventional video recording of clinical examination and is entirely ‘contactless'. This next generation technology holds potential for Parkinson's and other neurological disorders with altered movements.","Artificial intelligence,Bradykinesia,Computer vision,DeepLabCut,Finger tapping,Parkinson's disease,Parkinsonism","Cited By (since 2020): 41","",""
"Journal Article","Shao H,Pu J,Mu J","Pig-posture recognition based on computer vision: Dataset and exploration","Animals","2021","11","5","","","mdpi.com","","","2021","","2076-2615","http://dx.doi.org/10.3390/ani11051295","10.3390/ani11051295","","","","Posture changes in pigs during growth are often precursors of disease. Monitoring pigs' behavioral activities can allow us to detect pathological changes in pigs earlier and identify the factors threatening the health of pigs in advance. Pigs tend to be farmed on a large scale, and manual observation by keepers is time consuming and laborious. Therefore, the use of computers to monitor the growth processes of pigs in real time, and to recognize the duration and frequency of pigs' pos-tural changes over time, can prevent outbreaks of porcine diseases. The contributions of this article are as follows: (1) The first human-annotated pig-posture-identification dataset in the world was established, including 800 pictures of each of the four pig postures: standing, lying on the stomach, lying on the side, and exploring. (2) When using a deep separable convolutional network to classify pig postures, the accuracy was 92.45%. The results show that the method proposed in this paper achieves adequate pig-posture recognition in a piggery environment and may be suitable for livestock farm applications.","Agricultural automation,Automated breeding,Computer vision,Pig posture,Posture recognition","Cited By (since 2021): 19","",""
"Journal Article","Deepan P,Sudha LR","Deep Learning Algorithm and Its Applications to IoT and Computer Vision","Studies in Big Data","2021","85","","223-244","","Springer","","","2021","","2197-6511","https://link.springer.com/chapter/10.1007/978-981-33-6400-4_11;http://dx.doi.org/10.1007/978-981-33-6400-4_11","10.1007/978-981-33-6400-4_11","","","","Deep learning, which is the next phase of machine learning in recent decades, has significantly changed the way in which computer systems interpret human-centric content such as images, video, speech and audio. Different models have been introduced based on learning techniques such as supervised, unsupervised, reinforcement, and it is expected to accelerate and create even more innovative models in the coming years. With the rise of the Internet of Things (IoT), many real-time applications collect data about people and their environment using IoT sensors and feed them into deep learning models to enhance the intelligence and the capabilities of an application, for offering better recommendations and service. Experimental results of most of these applications looks promising when compared with traditional machine learning approaches. So, the main objective of this chapter is to make a self-contained review of Deep Learning (DL) models, starting with the Convolutioanl Neural Network (CNN), Recurrent Neural Network (RNN), Long-Term Short Memory (LSTM), AutoEncoder (AE), Generative Adversarial Network (GAN) and Deep Reinforcement Learning (DRL). Additionally, for providing better understanding of the models and their efficiency, we have added recently developed DL tools or framework and their applications.","Adversarial network and encoder,Convolutional network,Deep learning,Internet of Things,Recurrent network","Cited By (since 2021): 3","",""
"Miscellaneous","Sood S,Singh H","Computer Vision and Machine Learning based approaches for Food Security: A Review","","2021","80","18","27973-27999","","Springer","Multimedia Tools and Applications","","2021","","1573-7721","https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/article/10.1007/s11042-021-11036-2&casa_token=UKlEhf0qt6wAAAAA:ks2wLk2sQii_Q98EM0MkyJVbtoWg4odwFbecMonHoagEfdFaX__dQU-vK8BEtbox9aRNOo8x74MJZSKly0U;http://dx.doi.org/10.1007/s11042-021-11036-2","10.1007/s11042-021-11036-2","","","","With the rapidly increase of population every day, it has become a major issue to fulfill everyone's need for food products (i.e., vegetables, fruits, milk, wheat, etc.) due to limited production of food products. Moreover, healthy food utilization among people is the foremost requirement. The major factors that affect the food system includes increasing food shortage, decreasing quality, wastage, and loss of food products, limited natural resources, etc. This article addresses the various computer vision and machine learning based techniques, used to minimize the aforementioned issues. Image processing has become an effective technique for the analysis of many research applications. This study intends to focus on analysis of image processing based applications in food products and agriculture field. Such applications help in decision making , disease prediction, classification, fruit sorting, soil quality measurement, etc. Moreover, a comprehensive review has been accomplished for various computer vision and statistical approaches used in food production and agricultural field and concludes that Deep Learning (DL) based approaches produce better results, specifically for image processing applications. Additionally, an effort has been made to provide a list of publicly available datasets for the related study.","Convolutional neural network,Deep learning,Food Ssecurity,Smart farming","Cited By (since 2021): 14","",""
"Miscellaneous","Esteva A,Chou K,Yeung S,Naik N,Madani A,Mottaghi A,Liu Y,Topol E,Dean J,Socher R","Deep learning-enabled medical computer vision","","2021","4","1","","","nature.com","npj Digital Medicine","","2021","","2398-6352","https://www.nature.com/articles/s41746-020-00376-2;http://dx.doi.org/10.1038/s41746-020-00376-2","10.1038/s41746-020-00376-2","","","","A decade of unprecedented progress in artificial intelligence (AI) has demonstrated the potential for many fields—including medicine—to benefit from the insights that AI techniques can extract from data. Here we survey recent progress in the development of modern computer vision techniques—powered by deep learning—for medical applications, focusing on medical imaging, medical video, and clinical deployment. We start by briefly summarizing a decade of progress in convolutional neural networks, including the vision tasks they enable, in the context of healthcare. Next, we discuss several example medical imaging applications that stand to benefit—including cardiology, pathology, dermatology, ophthalmology–and propose new avenues for continued work. We then expand into general medical video, highlighting ways in which clinical workflows can integrate computer vision to enhance care. Finally, we discuss the challenges and hurdles required for real-world clinical deployment of these technologies.","computer vision,machine perception,medicine","Cited By (since 2021): 354","",""
"Journal Article","Alguliyev R,Imamverdiyev Y,Sukhostat L,Bayramov R","Plant disease detection based on a deep model","Soft Computing","2021","25","21","13229-13242","","mdpi.com","","","2021","","1433-7479","http://dx.doi.org/10.1007/s00500-021-06176-4","10.1007/s00500-021-06176-4","","","","Careful monitoring of plant conditions and their diagnosis are necessary, but a human cannot control a large area of land where the crop grows. This paper proposes the solution of this problem. Early diagnosis and accurate detection of plant leaf diseases can prevent the spread of the disease. In the last decade, machine learning methods and image classification tools have been used to identify and diagnose plant diseases. This paper proposes an accurate approach to identify plant leaf diseases based on the deep convolutional neural network and gated recurrent units. The PlantVillage dataset of damaged and healthy plant leaves images is used. The proposed model is trained to identify common plant leaf diseases of 14 species. The experimental results are compared to other well-known models. This study shows that the proposed model based on deep learning provides the best solution in the diagnosis of plant diseases with high accuracy, and that the gated recurrent unit neural network considered as a classifier can improve the accuracy of the convolutional neural network model. The comparison results demonstrated that the proposed approach achieved higher performance than other models.","Deep learning,Machine learning,Plant disease identification,Plant leaves","Cited By (since 2021): 48","",""
"Miscellaneous","Jorquera-Chavez M,Fuentes S,Dunshea FR,Warner RD,Poblete T,Unnithan RR,Morrison RS,Jongman EC","Using imagery and computer vision as remote monitoring methods for early detection of respiratory disease in pigs","","2021","187","","","","Elsevier","Computers and Electronics in Agriculture","","2021","","0168-1699","https://www.sciencedirect.com/science/article/pii/S0168169921003008?casa_token=RgnnuTNkBR4AAAAA:3QZwWABoX6Ldd2r2fpgKo_mTtPJbI_5XMjmfVIKepAslgF65wgoW1edgIf_oPzZkHPOsD1hWo6rY;http://dx.doi.org/10.1016/j.compag.2021.106283","10.1016/j.compag.2021.106283","","","","Respiratory diseases in pigs impact the wellbeing of animals and increase the cost of production. One of the most appropriate approaches to minimizing these negative effects is the early detection of ill animals. The use of cameras coupled with computer-based techniques could assist the early detection of physiological changes in pigs when they are beginning to become ill and prior to exhibiting clinical signs. This study consisted of two experiments that aimed to (a) evaluate the use of computer-based techniques over RGB (red, green, and blue) and thermal infrared imagery to measure heart rate and respiration rate of pigs, and (b) to investigate whether eye-temperature, heart rate and respiration rate assessed remotely could be used to identify early signs of respiratory diseases in free-moving, and group-housed growing pigs in a commercial piggery. In the first experiment, the remotely-obtained heart rate and respiration rate were compared with the measures obtained with standard methods, showing positive correlations (r = 0.61 – 0.66; p < 0.05). In the second experiment, pigs were recorded by overhead cameras and the remotely-obtained physiological measures were analysed to identify whether physiological changes could be detected in sick pigs before clinical signs were observed. The changes in eye-temperature and heart rate remotely obtained showed clear differences between sick and healthy pigs two days before clinical signs were detected. While significant changes in respiration rate occurred the day before clinical signs of illness were identified. The results of the present study indicate the possible use of computer vision technique for constant animal monitoring and rapid detection of physiological changes related to illness in commercial pigs. Further research is recommended to continue the development, automatization, and commercial practicality of this novel technology.","Animal health,Animal monitoring,Contactless monitoring,Non-invasive methods,Physiological indicators","Cited By (since 2021): 14","",""
"Miscellaneous","Abrami A,Gunzler S,Kilbane C,Ostrand R,Ho B,Cecchi G","Automated computer vision assessment of hypomimia in parkinson disease: Proof-of-principle pilot study","","2021","23","2","","","jmir.org","Journal of Medical Internet Research","","2021","","1438-8871","https://www.jmir.org/2021/2/e21037/;http://dx.doi.org/10.2196/21037;https://www.ncbi.nlm.nih.gov/pubmed/33616535","10.2196/21037","33616535","","","Background: Facial expressions require the complex coordination of 43 different facial muscles. Parkinson disease (PD) affects facial musculature leading to “hypomimia” or “masked facies.” Objective: We aimed to determine whether modern computer vision techniques can be applied to detect masked facies and quantify drug states in PD. Methods: We trained a convolutional neural network on images extracted from videos of 107 self-identified people with PD, along with 1595 videos of controls, in order to detect PD hypomimia cues. This trained model was applied to clinical interviews of 35 PD patients in their on and off drug motor states, and seven journalist interviews of the actor Alan Alda obtained before and after he was diagnosed with PD. Results: The algorithm achieved a test set area under the receiver operating characteristic curve of 0.71 on 54 subjects to detect PD hypomimia, compared to a value of 0.75 for trained neurologists using the United Parkinson Disease Rating Scale-III Facial Expression score. Additionally, the model accuracy to classify the on and off drug states in the clinical samples was 63% (22/35), in contrast to an accuracy of 46% (16/35) when using clinical rater scores. Finally, each of Alan Alda's seven interviews were successfully classified as occurring before (versus after) his diagnosis, with 100% accuracy (7/7). Conclusions: This proof-of-principle pilot study demonstrated that computer vision holds promise as a valuable tool for PD hypomimia and for monitoring a patient's motor state in an objective and noninvasive way, particularly given the increasing importance of telemedicine.","Computer vision,Hypomimia,Parkinson disease,Telemedicine","Cited By (since 2021): 10","",""
"Journal Article","Aboneh T,Rorissa A,Srinivasagan R,Gemechu A","Computer Vision Framework for Wheat Disease Identification and Classification Using Jetson GPU Infrastructure","Technologies","2021","9","3","47","","mdpi.com","","","2021","","2227-7080","http://dx.doi.org/10.3390/technologies9030047","10.3390/technologies9030047","","","","Diseases have adverse effects on crop production and yield loss. Various diseases such as leaf rust, stem rust, and strip rust can affect yield quality and quantity for a studied area. In addition, manual wheat disease identification and interpretation is time-consuming and cumbersome. Currently, decisions related to plants mainly rely on the level of expertise in the domain. To resolve these challenges and to identify wheat disease as early as possible, we implemented different deep learning models such as Inceptionv3, Resnet50, and VGG16/19. This research was conducted in collaboration with Bishoftu Agricultural Research Institute, Ethiopia. Our main objective was to automate plant-disease identification using advanced deep learning approaches and image data. For the experiment, RGB image data were collected from the Bishoftu area. From the experimental results, the VGG19 model classified wheat disease with 99.38% accuracy.","agriculture,computer vision,deep learning model,wheat disease","Cited By (since 2021): 13","",""
"Journal Article","Ouhami M,Hafiane A,Es-Saady Y,El Hajji M,Canals R","Computer vision, IoT and data fusion for crop disease detection using machine learning: A survey and ongoing research","Remote Sensing","2021","13","13","","","mdpi.com","","","2021","","2072-4292","http://dx.doi.org/10.3390/rs13132486","10.3390/rs13132486","","","","Crop diseases constitute a serious issue in agriculture, affecting both quality and quantity of agriculture production. Disease control has been a research object in many scientific and technologic domains. Technological advances in sensors, data storage, computing resources and artificial intelligence have shown enormous potential to control diseases effectively. A growing body of literature recognizes the importance of using data from different types of sensors and machine learning approaches to build models for detection, prediction, analysis, assessment, etc. However, the increasing number and diversity of research studies requires a literature review for further developments and contributions in this area. This paper reviews state-of-the-art machine learning methods that use different data sources, applied to plant disease detection. It lists traditional and deep learning methods associated with the main data acquisition modalities, namely IoT, ground imaging, unmanned aerial vehicle imaging and satellite imaging. In addition, this study examines the role of data fusion for ongoing research in the context of disease detection. It highlights the advantage of intelligent data fusion techniques, from heterogeneous data sources, to improve plant health status prediction and presents the main challenges facing this field. The study concludes with a discussion of several current issues and research trends.","Data fusion,Intelligent sensors,Machine learning,Plant disease,Remote sensing","Cited By (since 2021): 44","",""
"Journal Article","Rupprechter S,Morinan G,Peng Y,Foltynie T,Sibley K,Weil RS,Leyland LA,Baig F,Morgante F,Gilron R,Wilt R,Starr P,Hauser RA,O'Keeffe J","A clinically interpretable computer-vision based method for quantifying gait in parkinson's disease","Sensors","2021","21","16","","","mdpi.com","","","2021","","1424-8220","http://dx.doi.org/10.3390/s21165437;https://www.ncbi.nlm.nih.gov/pubmed/34450879","10.3390/s21165437","34450879","","","Gait is a core motor function and is impaired in numerous neurological diseases, including Parkinson's disease (PD). Treatment changes in PD are frequently driven by gait assessments in the clinic, commonly rated as part of the Movement Disorder Society (MDS) Unified PD Rating Scale (UPDRS) assessment (item 3.10). We proposed and evaluated a novel approach for estimating severity of gait impairment in Parkinson's disease using a computer vision-based methodology. The system we developed can be used to obtain an estimate for a rating to catch potential errors, or to gain an initial rating in the absence of a trained clinician—for example, during remote home assessments. Videos (n = 729) were collected as part of routine MDS-UPDRS gait assessments of Parkinson's patients, and a deep learning library was used to extract body key-point coordinates for each frame. Data were recorded at five clinical sites using commercially available mobile phones or tablets, and had an associated severity rating from a trained clinician. Six features were calculated from time-series signals of the extracted key-points. These features characterized key aspects of the movement including speed (step frequency, estimated using a novel Gamma-Poisson Bayesian model), arm swing, postural control and smoothness (or roughness) of movement. An ordinal random forest classification model (with one class for each of the possible ratings) was trained and evaluated using 10-fold cross validation. Step frequency point estimates from the Bayesian model were highly correlated with manually labelled step frequencies of 606 video clips showing patients walking towards or away from the camera (Pearson's r = 0.80, p < 0.001). Our classifier achieved a balanced accuracy of 50% (chance = 25%). Estimated UPDRS ratings were within one of the clinicians' ratings in 95% of cases. There was a significant correlation between clinician labels and model estimates (Spearman's $\rho$ = 0.52, p < 0.001). We show how the interpretability of the feature values could be used by clinicians to support their decision-making and provide insight into the model's objective UPDRS rating estimation. The severity of gait impairment in Parkinson's disease can be estimated using a single patient video, recorded using a consumer mobile device and within standard clinical settings; i.e., videos were recorded in various hospital hallways and offices rather than gait laboratories. This approach can support clinicians during routine assessments by providing an objective rating (or second opinion), and has the potential to be used for remote home assessments, which would allow for more frequent monitoring.","Computer vision,Gait,Interpretable machine learning,Parkinson's disease,Pose estimation,Time series analysis","Cited By (since 2021): 18","",""
"Miscellaneous","Olveres J,González G,Torres F,Moreno-Tagle JC,Carbajal-Degante E,Valencia-Rodríguez A,Méndez-Sánchez N,Escalante- Ramírez B","What is new in computer vision and artificial intelligence in medical image analysis applications","","2021","11","8","3830-3853","","ncbi.nlm.nih.gov","Quantitative Imaging in Medicine and Surgery","","2021","","2223-4306","https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8245941/;http://dx.doi.org/10.21037/qims-20-1151;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8245941","10.21037/qims-20-1151","","","PMC8245941","Computer vision and artificial intelligence applications in medicine are becoming increasingly important day by day, especially in the field of image technology. In this paper we cover different artificial intelligence advances that tackle some of the most important worldwide medical problems such as cardiology, cancer, dermatology, neurodegenerative disorders, respiratory problems, and gastroenterology. We show how both areas have resulted in a large variety of methods that range from enhancement, detection, segmentation and characterizations of anatomical structures and lesions to complete systems that automatically identify and classify several diseases in order to aid clinical diagnosis and treatment. Different imaging modalities such as computer tomography, magnetic resonance, radiography, ultrasound, dermoscopy and microscopy offer multiple opportunities to build automatic systems that help medical diagnosis, taking advantage of their own physical nature. However, these imaging modalities also impose important limitations to the design of automatic image analysis systems for diagnosis aid due to their inherent characteristics such as signal to noise ratio, contrast and resolutions in time, space and wavelength. Finally, we discuss future trends and challenges that computer vision and artificial intelligence must face in the coming years in order to build systems that are able to solve more complex problems that assist medical diagnosis.","Artificial intelligence (AI),Cardiology,Computer vision (CV),Gastroenterology,Medical image analysis,Microscopy,Neurodegenerative disorders,Oncology,Respiratory diseases","Cited By (since 2021): 15","",""
"Miscellaneous","Vo TT,Ko H,Huh JH,Kim Y","Overview of smart aquaculture system: Focusing on applications of machine learning and computer vision","","2021","10","22","","","mdpi.com","Electronics (Switzerland)","","2021","","2079-9292","https://www.mdpi.com/1370442;http://dx.doi.org/10.3390/electronics10222882","10.3390/electronics10222882","","","","Smart aquaculture is nowadays one of the sustainable development trends for the aquaculture industry in intelligence and automation. Modern intelligent technologies have brought huge benefits to many fields including aquaculture to reduce labor, enhance aquaculture production, and be friendly to the environment. Machine learning is a subdivision of artificial intelligence (AI) by using trained algorithm models to recognize and learn traits from the data it watches. To date, there are several studies about applications of machine learning for smart aquaculture including measuring size, weight, grading, disease detection, and species classification. This review provides and overview of the development of smart aquaculture and intelligent technology. We summarized and collected 100 articles about machine learning in smart aquaculture from nearly 10 years about the methodology, results as well as the recent technology that should be used for development of smart aquaculture. We hope that this review will give readers interested in this field useful information.","AI,Application,Artificial intelligent,Machine learning,Smart aquaculture","Cited By (since 2021): 11","",""
"Journal Article","Hridoy RH,Akter F,Mahfuzullah M,Ferdowsy F","A Computer Vision Based Food Recognition Approach for Controlling Inflammation to Enhance Quality of Life of Psoriasis Patients","2021 International Conference on Information Technology, ICIT 2021 - Proceedings","2021","","","543-548","","ieeexplore.ieee.org","","","2021","","","http://dx.doi.org/10.1109/ICIT52682.2021.9491783","10.1109/ICIT52682.2021.9491783","","","","Deep learning becomes the spotlight in computer vision based recognition approaches in recent years. Psoriasis affects people of all ages around the world and causes inflammation on the skin with significant systemic disability and illness. Inflammatory foods increase inflammation rapidly, patients can easily control inflammation to enhance the quality of life by eliminating these foods from their everyday diet. This paper addresses a rapid food recognition approach to assist psoriasis patients to recognize fifteen highly inflammatory foods. Using image augmentation techniques, a dataset of 41250 images of different inflammatory foods have generated from 10000 images. AlexNet, VGG16, and EfficientNet-B0 have used in this study using the transfer learning approach, and EfficientNet-B0 has achieved the highest accuracy of 98.63% under the test set of 5250 images. AlexNet and VGG16 have achieved 87.22% and 93.79% accuracy, respectively. EfficientNet-B0 has consumed the lowest time in recognizing unseen images compared to others.","Computer Vision,Deep Learning,Food Recognition,Psoriasis,Transfer Learning","Cited By (since 2021): 7","",""
"Journal Article","Su WH,Zhang J,Yang C,Page R,Szinyei T,Hirsch CD,Steffenson BJ","Automatic evaluation of wheat resistance to fusarium head blight using dual mask-rcnn deep learning frameworks in computer vision","Remote Sensing","2021","13","1","1-20","","mdpi.com","","","2021","","2072-4292","http://dx.doi.org/10.3390/rs13010026","10.3390/rs13010026","","","","In many regions of the world, wheat is vulnerable to severe yield and quality losses from the fungus disease of Fusarium head blight (FHB). The development of resistant cultivars is one means of ameliorating the devastating effects of this disease, but the breeding process requires the evaluation of hundreds of lines each year for reaction to the disease. These field evaluations are laborious, expensive, time-consuming, and are prone to rater error. A phenotyping cart that can quickly capture images of the spikes of wheat lines and their level of FHB infection would greatly benefit wheat breeding programs. In this study, mask region convolutional neural network (MaskRCNN) allowed for reliable identification of the symptom location and the disease severity of wheat spikes. Within a wheat line planted in the field, color images of individual wheat spikes and their corresponding diseased areas were labeled and segmented into sub-images. Images with annotated spikes and sub-images of individual spikes with labeled diseased areas were used as ground truth data to train Mask-RCNN models for automatic image segmentation of wheat spikes and FHB diseased areas, respectively. The feature pyramid network (FPN) based on ResNet-101 network was used as the backbone of Mask-RCNN for constructing the feature pyramid and extracting features. After generating mask images of wheat spikes from full-size images, Mask-RCNN was performed to predict diseased areas on each individual spike. This protocol enabled the rapid recognition of wheat spikes and diseased areas with the detection rates of 77.76% and 98.81%, respectively. The prediction accuracy of 77.19% was achieved by calculating the ratio of the wheat FHB severity value of prediction over ground truth. This study demonstrates the feasibility of rapidly determining levels of FHB in wheat spikes, which will greatly facilitate the breeding of resistant cultivars.","Computer vision,Deep learning,Fusarium head blight,Target recognition,Wheat spike","Cited By (since 2020): 53","",""
"Journal Article","Khan AA,Laghari AA,Awan SA","Machine Learning in Computer Vision: A Review","EAI Endorsed Transactions on Scalable Information Systems","2021","8","32","1-11","","publications.eai.eu","","","2021","","2032-9407","http://dx.doi.org/10.4108/eai.21-4-2021.169418","10.4108/eai.21-4-2021.169418","","","","INTRODUCTION: Due to the advancement in the field of Artificial Intelligence (AI), the ability to tackle entire problems of machine intelligence. Nowadays, Machine learning (ML) is becoming a hot topic due to the direct training of machines with less interaction with a human. The scenario of manual feeding of the machine is changed in the modern era, it will learn automatically. Supervised and unsupervised ML techniques are used as a distinct purpose like feature extraction, pattern recognition, object detection, and classification. OBJECTIVES: In Computer Vision (CV), ML performs a significant role to extract crucial information from images. CV successfully contributes to multiple domains, surveillance system, optical character recognition, robotics, suspect detection, and many more. The direction of CV research is going toward healthcare realm, medical imaging (MI) is the emerging technology, play a vital role to enhance image quality and recognized critical features of binary medical image, covert original image into grayscale and set the threshold values for segmentation. CONTRIBUTION: This paper will address the importance of machine learning, state-of-the-art, and how ML is utilized in computer vision and image processing. This survey will provide details about the type of tools and applications, datasets, and techniques. Limitations of previous work and challenges of future work also discussed. Further, we identify and discuss a set of open issues yet to be addressed, for efficiently applying of ML in Computer vision and image process. METHODS, RESULTS, AND CONCLUSION: In this review paper, we have discussed the techniques and various types of supervised and unsupervised algorithms of ML, general overview of image processing and the results based on the impact; neural network enabled models, limitations, tools and application of CV, moreover, highlight the critical open research areas of ML in CV.","Computer Vision,Feature Extraction,Machine Learning,Medical Imaging,Neural Network,Pattern Recognition,Supervised and Unsupervised Learning","Cited By (since 2021): 34","",""
"Miscellaneous","Bhargava A,Bansal A","Novel coronavirus (COVID-19) diagnosis using computer vision and artificial intelligence techniques: a review","","2021","80","13","19931-19946","","Springer","Multimedia Tools and Applications","","2021","","1573-7721","https://link.springer.com/article/10.1007/s11042-021-10714-5;http://dx.doi.org/10.1007/s11042-021-10714-5","10.1007/s11042-021-10714-5","","","","The universal transmission of pandemic COVID-19 (Coronavirus) causes an immediate need to commit in the fight across the whole human population. The emergencies for human health care are limited for this abrupt outbreak and abandoned environment. In this situation, inventive automation like computer vision (machine learning, deep learning, artificial intelligence), medical imaging (computed tomography, X-Ray) has developed an encouraging solution against COVID-19. In recent months, different techniques using image processing are done by various researchers. In this paper, a major review on image acquisition, segmentation, diagnosis, avoidance, and management are presented. An analytical comparison of the various proposed algorithm by researchers for coronavirus has been carried out. Also, challenges and motivation for research in the future to deal with coronavirus are indicated. The clinical impact and use of computer vision and deep learning were discussed and we hope that dermatologists may have better understanding of these areas from the study.","COVID-19,Computed tomography,Computer vision,Coronavirus,Machine learning","Cited By (since 2021): 42","",""
"Journal Article","Wangsan K,Upaphong P,Assavanopakun P,Sapbamrer R,Sirikul W,Kitro A,Sirimaharaj N,Kuanprasert S,Saenpo M,Saetiao S,Khamphichai T","Self-Reported Computer Vision Syndrome among Thai University Students in Virtual Classrooms during the COVID-19 Pandemic: Prevalence and Associated Factors","International Journal of Environmental Research and Public Health","2022","19","7","","","mdpi.com","","","2022","","1660-4601","http://dx.doi.org/10.3390/ijerph19073996;https://www.ncbi.nlm.nih.gov/pubmed/35409679","10.3390/ijerph19073996","35409679","","","During the COVID-19 pandemic, computer vision syndrome (CVS) related to online classrooms were unavoidable. This cross-sectional study aimed to explore the prevalence, characteristics and associated factors of CVS. A total of 527 students who were currently studying in a virtual classroom (70.40% female, mean (standard deviation; SD) age of 20.04 (2.17) years) were included. The prevalence of CVS assessed by an online CVS-Questionnaire was 81.0% (427/527). Comparing with those in the period before the online study, an increase in screen time (interquartile range) in students with and without CVS was 3 (0–3) and 2 (1–5) h, respectively. Overall, 516 students (97.9%) experienced at least one symptom. The most frequent symptom in CVS subjects was eye pain (96.5%). The most intense symptoms were the feeling of worsening eyesight (15.9%). The factors associated with CVS were female (p < 0.001), age (p = 0.010), atopic diseases (p = 0.020), prior ocular symptoms (p < 0.001), astigmatism (p = 0.033), distance from display <20 cm (p = 0.023), presence of glare or reflection on screen (p < 0.001), low screen brightness (p = 0.045), sleep duration (p = 0.030), inadequate break time between classes (p < 0.001) and increased screen time usage during online study (p < 0.001). Recommendations to prevent CVS based on the adjustable factors might reduce the burden of online study.","COVID-19 impact,computer vison syndrome,digital eye strain,digital screen,online study,video display terminal,virtual classroom,visual display terminal","Cited By (since 2022): 16","",""
"Journal Article","Luo C,Pearson P,Xu G,Rich SM","A Computer Vision-Based Approach for Tick Identification Using Deep Learning Models","Insects","2022","13","2","","","mdpi.com","","","2022","","2075-4450","http://dx.doi.org/10.3390/insects13020116","10.3390/insects13020116","","","","A wide range of pathogens, such as bacteria, viruses, and parasites can be transmitted by ticks and can cause diseases, such as Lyme disease, anaplasmosis, or Rocky Mountain spotted fever. Landscape and climate changes are driving the geographic range expansion of important tick species. The morphological identification of ticks is critical for the assessment of disease risk; however, this process is time-consuming, costly, and requires qualified taxonomic specialists. To address this issue, we constructed a tick identification tool that can differentiate the most encountered human-biting ticks, Amblyomma americanum, Dermacentor variabilis, and Ixodes scapularis, by implementing artificial intelligence methods with deep learning algorithms. Many convolutional neural network (CNN) models (such as VGG, ResNet, or Inception) have been used for image recognition purposes but it is still a very limited application in the use of tick identification. Here, we describe the modified CNN-based models which were trained using a large-scale molecularly verified dataset to identify tick species. The best CNN model achieved a 99.5% accuracy on the test set. These results demonstrate that a computer vision system is a potential alternative tool to help in prescreening ticks for identification, an earlier diagnosis of disease risk, and, as such, could be a valuable resource for health professionals.","Computer vision,Medical entomology,Ticks","Cited By (since 2022): 2","",""
"Journal Article","Vij R,Arora S","Computer Vision with Deep Learning Techniques for Neurodegenerative Diseases Analysis Using Neuroimaging: A Survey","International Conference on Innovative Computing and \ldots","2022","","","179-189","","Springer","","","2022","","","http://dx.doi.org/10.1007/978-981-16-2597-8_15","10.1007/978-981-16-2597-8_15","","","","\ldots diseases has attracted the focus of several researchers. This paper surveys the various applications of computer vision \ldots the performance of computer vision approaches for more efficient \ldots","Artificial intelligence,Computer vision,Deep learning,Medical imaging modalities,Neurodegenerative diseases,Neuroimages","Cited By (since 2022): 6","",""
"Miscellaneous","Adane F,Alamneh YM,Desta M","Computer vision syndrome and predictors among computer users in Ethiopia: a systematic review and meta-analysis","","2022","50","1","","","Springer","Tropical Medicine and Health","","2022","","1349-4147","https://link.springer.com/article/10.1186/s41182-022-00418-3;http://dx.doi.org/10.1186/s41182-022-00418-3","10.1186/s41182-022-00418-3","","","","Background: A computer is one of the most widely used office tools. The leading occupational health problem of the twenty-first century is computer vision syndrome (CVS). Research findings across Ethiopia on the magnitude and predictors of CVS among computer users are highly variable and inconsistent. Therefore, this study aimed to estimate the overall prevalence of CVS and its predictors among computer users in Ethiopia. Methods: We searched articles in all databases and other sources. Cochrane Q test statistics and I2 tests were used. A random-effect meta-analysis model was used. In addition, the association between risk factors and CVS among computer users was examined. Results: Eight eligible studies were included. The pooled prevalence of CVS among computer users in Ethiopia was 73.21% (95% CI 70.32–76.11). Sub-group analysis by profession has shown that the highest prevalence of CVS was observed in bank employees [73.76% (95% CI 70.40–77.13)]. The most common reported symptoms of CVS were blurred vision (34.26%; 95% CI 22.08, 46.43). The previous history of eye disease (95% CI 2.30, 5.47), inappropriate sitting position (95% CI 1.76, 3.22), the frequent use of a computer (95% CI 2.04, 3.60), and using eyeglass/spectacles (95% CI 1.10, 3.91) were significantly associated with CVS among computer users in Ethiopia. Conclusions: According to this study, computer vision syndrome was high among computer users in Ethiopia. Computer vision syndrome (CVS) was significantly associated with a previous history of eye disease, inappropriate sitting position, frequent use of a computer, and the use of spectacles. Based on the findings, it is suggested that efforts be made to optimize computer exposure time. It is also worth noting that employees should be properly seated when using a computer. Furthermore, people with vision problems should be extra cautious when using a computer. Finally, community awareness of the safety precautions that can be taken to reduce CVS is critical.","Bankers,CVS,Computer vision syndrome,Employees,Meta-analysis and Ethiopia,Secretaries,System review","Cited By (since 2022): 9","",""
"Miscellaneous","Abbaspour-Gilandeh Y,Aghabara A,Davari M,Maja JM","Feasibility of Using Computer Vision and Artificial Intelligence Techniques in Detection of Some Apple Pests and Diseases","","2022","12","2","","","mdpi.com","Applied Sciences (Switzerland)","","2022","","2076-3417","https://www.mdpi.com/1452694;http://dx.doi.org/10.3390/app12020906","10.3390/app12020906","","","","There are many methods to detect plant pests and diseases, but they are primarily time-consuming and costly. Computer vision techniques can recognize the pest-and disease-damaged fruits and provide clues to identify and treat the diseases and pests in their early stages. This study aimed to identify common pests, including the apple capsid (Plesiocoris rugicollis)/AC, apple codling moth (Cydia pomonella)/ACM, Pear lace bug (Stephanitis pyri)/PLB, and one physiological disease-apple russeting/AR in two cultivars, Golden Delicious and Red Delicious, using the digital image processing and sparse coding method. The Sparse coding method is used to reduce the storage of the elements of images so that the matrix can be processed faster. There have been numerous studies on the identification of apple fruit diseases and pests. However, most of the previous studies focused only on diagnosing a pest or disease, not on computational volume reduction and rapid detection. This research focused on the comprehensive study on identifying pests and diseases of apple fruit using sparse coding. The sparse coding algorithm in this work was designed using Matlab software. The apple pest and disease detection were performed based on 11 characteristics: R, G, B, L, a, b, H, S, V, Sift, and Harris. The class detection accuracy using the sparse coding method was obtained for 10 classes with three views of apple for S. pyri of red apple as 81%, S. pyri of golden apple as 88%, golden apple russeting as 85%, S. pyri and russeting of red apple as 100%, S. pyri and russeting of golden apple as 80%, codling moth of red apple as 86%, codling moth of golden apple as 72%, S. pyri of red apple as 83%, S. pyri of golden apple as 90%, codling moth and S. pyri of red apple as 80%, and codling moth and S. pyri of golden apple as 67%. The total processing time for developing the dictionary was 220 s. Once the dictionary was developed, pest and disease detection took only 0.175 s. The results of this study can be useful in developing automatic devices for the early detection of common pests and diseases of apples. Although the study was focused on apple diseases, results for this work have huge potential for other crops.","Apple capsid,Apple russeting,Early detection,Image processing,Pest,Sparse coding","Cited By (since 2022): 5","",""
"Journal Article","Akbarian S,Nelder MP,Russell CB,Cawston T,Moreno L,Patel SN,Allen VG,Dolatabadi E","A Computer Vision Approach to Identifying Ticks Related to Lyme Disease","IEEE Journal of Translational Engineering in Health and Medicine","2022","10","","","","ieeexplore.ieee.org","","","2022","","2168-2372","http://dx.doi.org/10.1109/JTEHM.2021.3137956;https://www.ncbi.nlm.nih.gov/pubmed/35492508","10.1109/JTEHM.2021.3137956","35492508","","","Background: Lyme disease (caused by Borrelia burgdorferi) is an infectious disease transmitted to humans by a bite from infected blacklegged ticks (Ixodes scapularis) in eastern North America. Lyme disease can be prevented if antibiotic prophylaxis is given to a patient within 72 hours of a blacklegged tick bite. Therefore, recognizing a blacklegged tick could facilitate the management of Lyme disease. Methods: In this work, we build an automated detection tool that can differentiate blacklegged ticks from other tick species using advanced computer vision approaches in real-time. Specially, we use convolution neural network models, trained end-to-end, to classify tick species. Also, advanced knowledge transfer techniques are adopted to improve the performance of convolution neural network models. Results: Our best convolution neural network model achieves 92% accuracy on unseen tick species. Conclusion: Our proposed vision-based approach simplifies tick identification and contributes to the emerging work on public health surveillance of ticks and tick-borne diseases. In addition, it can be integrated with the geography of exposure and potentially be leveraged to inform the risk of Lyme disease infection. This is the first report of using deep learning technologies to classify ticks, providing the basis for automation of tick surveillance, and advancing tick-borne disease ecology and risk management.","Computer vision,Ixodes scapularis,Lyme disease,convolution neural network,infectious disease,knowledge transfer,public health,surveillance,vector-borne disease","Cited By (since 2021): 1","",""
"Miscellaneous","Uryasheva A,Kalashnikova A,Shadrin D,Evteeva K,Moskovtsev E,Rodichenko N","Computer vision-based platform for apple leaves segmentation in field conditions to support digital phenotyping","","2022","201","","","","Elsevier","Computers and Electronics in Agriculture","","2022","","0168-1699","https://www.sciencedirect.com/science/article/pii/S0168169922005828?casa_token=U1tMSiyOURsAAAAA:Cl-bfQfxO6jWp20e_b-ssmgIwuXNzrK0xWmjmDfF1smsoybQIt5jn-DO6-I59WTNoOUDEK0sCHjc;http://dx.doi.org/10.1016/j.compag.2022.107269","10.1016/j.compag.2022.107269","","","","Computer vision and machine learning have recently been applied to a number of sensing platforms, boosting their performance to a new level. These advances have shown the vast possibilities for enhancing remote plant health assessment and disease detection. Until now, however, the scanning time and spatial resolution of such automated tools have been limited, as well as the area of application. We developed a state-of-the-art sensing system equipped with artificial intelligence and multispectral imaging with a special focus on near real-time and universality of application in agriculture. For this purpose, we collected a dataset of over 360,000 images of healthy and infected apple trees to develop and test our system, which includes a Convolutional Neural Network (CNN) algorithm for leaves segmentation. The proposed solution automatically computed vegetation indices (VIs) accurate to a single pixel. Further, we developed a desktop application for data post-processing and visualization, which allows the user to rapidly assess the health status of a vast agricultural area and thoroughly examine each tree individually. The developed system was successfully tested under field conditions in a large apple orchard, confirming viability of a reliable, end-to-end solution based on a computer vision platform for remote assessment of plant health and identification of stressed plants with high precision and spatial resolution.","Computer vision,Image processing,Plant disease detection,Precision agriculture,Remote sensing","Cited By (since 2022): 1","",""
"Miscellaneous","Khanal SR,Paulino D,Sampaio J,Barroso J,Reis A,Filipe V","A Review on Computer Vision Technology for Physical Exercise Monitoring","","2022","15","12","","","mdpi.com","Algorithms","","2022","","1999-4893","https://www.mdpi.com/1999-4893/15/12/444;http://dx.doi.org/10.3390/a15120444","10.3390/a15120444","","","","Physical activity is movement of the body or part of the body to make muscles more active and to lose the energy from the body. Regular physical activity in the daily routine is very important to maintain good physical and mental health. It can be performed at home, a rehabilitation center, gym, etc., with a regular monitoring system. How long and which physical activity is essential for specific people is very important to know because it depends on age, sex, time, people that have specific diseases, etc. Therefore, it is essential to monitor physical activity either at a physical activity center or even at home. Physiological parameter monitoring using contact sensor technology has been practiced for a long time, however, it has a lot of limitations. In the last decades, a lot of inexpensive and accurate non-contact sensors became available on the market that can be used for vital sign monitoring. In this study, the existing research studies related to the non-contact and video-based technologies for various physiological parameters during exercise are reviewed. It covers mainly Heart Rate, Respiratory Rate, Heart Rate Variability, Blood Pressure, etc., using various technologies including PPG, Video analysis using deep learning, etc. This article covers all the technologies using non-contact methods to detect any of the physiological parameters and discusses how technology has been extended over the years. The paper presents some introductory parts of the corresponding topic and state of art review in that area.","computer vision,contactless technology,deep learning,exercise monitoring,physical activity,vital sign monitoring","","",""
"Miscellaneous","Alhasan AS,Aalam WA","Magnitude and Determinants of Computer Vision Syndrome Among Radiologists in Saudi Arabia: A National Survey","","2022","29","9","e197-e204","","Elsevier","Academic Radiology","","2022","","1878-4046","https://www.sciencedirect.com/science/article/pii/S1076633221004967;http://dx.doi.org/10.1016/j.acra.2021.10.023;https://www.ncbi.nlm.nih.gov/pubmed/34836777","10.1016/j.acra.2021.10.023","34836777","","","Rationale and Objectives: To assess the magnitude and determinants of computer vision syndrome (CVS) among radiologists in Saudi Arabia using a reliable and validated survey instrument. Materials and Methods: This nationwide cross-sectional web-based survey took place in April 2021 and included all radiologists and radiology residents residing practicing in Saudi Arabia. We used the reliable and validated CVS questionnaire. Univariate and multivariate analyses were carried out using nonparametric methods. The CVS score was correlated with different demographic- and health-related variables. The Mann-Whitney U test and Kruskal-Wallis test were used to determine if there was a statistically significant difference between subgroups. Results: The survey was completed by 416 participants. The prevalence of CVS was 65.4% (95% CI: 60.8-70.0). The median CVS score was 7.5 (interquartile range: 4.0; 12.0). Mild CVS was observed in 188 participants (69.1%), moderate CVS was observed in 69 (25.4%), and severe CVS was observed in 15 (5.5%). The most common symptoms perceived by participants were headache (72.1%), dryness (70.7%), burning (63.7%), blurred vision (56.3%), and increased sensitivity to light (55.5%). Multinomial regression analysis suggested that female sex (p < 0.001), work as a general radiologist (p = 0.05), and the use of eyeglasses (p = 0.001) were significant predictors of CVS. Conclusion: The prevalence of CVS among radiologists in our study was high. Local and international societies need to establish and implement legislative and preventive measures to ensure the safety and ocular and visual health of radiologists.","Computer Vision Syndrome,Eyestrain,Occupational hazards,Radiologists,Saudi Arabia","Cited By (since 2022): 8","",""
"Miscellaneous","Hassan H,Ren Z,Zhao H,Huang S,Li D,Xiang S,Kang Y,Chen S,Huang B","Review and classification of AI-enabled COVID-19 CT imaging models based on computer vision tasks","","2022","141","","","","Elsevier","Computers in Biology and Medicine","","2022","","1879-0534","https://www.sciencedirect.com/science/article/pii/S0010482521009173;http://dx.doi.org/10.1016/j.compbiomed.2021.105123;https://www.ncbi.nlm.nih.gov/pubmed/34953356","10.1016/j.compbiomed.2021.105123","34953356","","","This article presents a systematic overview of artificial intelligence (AI) and computer vision strategies for diagnosing the coronavirus disease of 2019 (COVID-19) using computerized tomography (CT) medical images. We analyzed the previous review works and found that all of them ignored classifying and categorizing COVID-19 literature based on computer vision tasks, such as classification, segmentation, and detection. Most of the COVID-19 CT diagnosis methods comprehensively use segmentation and classification tasks. Moreover, most of the review articles are diverse and cover CT as well as X-ray images. Therefore, we focused on the COVID-19 diagnostic methods based on CT images. Well-known search engines and databases such as Google, Google Scholar, Kaggle, Baidu, IEEE Xplore, Web of Science, PubMed, ScienceDirect, and Scopus were utilized to collect relevant studies. After deep analysis, we collected 114 studies and reported highly enriched information for each selected research. According to our analysis, AI and computer vision have substantial potential for rapid COVID-19 diagnosis as they could significantly assist in automating the diagnosis process. Accurate and efficient models will have real-time clinical implications, though further research is still required. Categorization of literature based on computer vision tasks could be helpful for future research; therefore, this review article will provide a good foundation for conducting such research.","COVID-19,COVID-19 classification,COVID-19 detection,COVID-19 diagnosis,Image segmentation","Cited By (since 2022): 20","",""
"Miscellaneous","Devi N,Sarma KK,Laskar S","Design of an intelligent bean cultivation approach using computer vision, IoT and spatio-temporal deep learning structures","","2023","","","","","Elsevier","Ecological Informatics","","2023","","","https://www.sciencedirect.com/science/article/pii/S1574954123000730","","","","","\ldots Results show that our proposed DL models could accurately predict the health state of the bean leaves with less computation time. With an automated approach of bean leaf health \ldots","Artificial intelligence,Convolution neural network,Learning based system,Smart farming","","",""
